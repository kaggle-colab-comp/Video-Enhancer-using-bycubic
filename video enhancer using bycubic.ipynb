{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae64936",
   "metadata": {},
   "source": [
    "### Installlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79852c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a0fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a778ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be72be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1660 SUPER\n",
      "Using device: cuda\n",
      "‚úÖ Torchvision functional module is working!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# ‚úÖ Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "from torchvision.transforms import v2\n",
    "print(\"‚úÖ Torchvision functional module is working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5148a2",
   "metadata": {},
   "source": [
    "# enhancement code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5b2e8b-62ce-461e-a3a7-268fbc7f8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import ipywidgets as widgets\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531c40c-6164-4b4e-b8b9-bebe2f10b2c8",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è STEP 1: Load/Define Super-Resolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b2c81ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Upscale model ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup dummy model (replace later with real SR model)\n",
    "class UpscaleModel(torch.nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.upscale = torch.nn.Upsample(scale_factor=scale_factor, mode='bicubic', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upscale(x)\n",
    "\n",
    "# Instantiate and move model to GPU (if available)\n",
    "model = UpscaleModel(scale_factor=2).to(device)\n",
    "model.eval()\n",
    "print(\"‚úÖ Upscale model ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079dcb8-1dbc-4aca-9cad-121b60e7b864",
   "metadata": {},
   "source": [
    "## üé• STEP 2: Load Video, Process, and Save Upscaled Output  (Frame Processing + Muxing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0f4b7c-5923-4ea5-868b-e7f80bc8f1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def377001f6c4dc6ad0921f177700512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upscaling frames:   0%|          | 0/42379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video upscaled and saved to: temp_upscaled.mp4\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Upscale frames and merge audio/subs\n",
    "\n",
    "input_path = 'naruto.mkv'\n",
    "temp_upscaled_path = 'temp_upscaled.mp4'\n",
    "final_output_path = 'naruto_upscaled.mkv'\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Output writer\n",
    "out = cv2.VideoWriter(temp_upscaled_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width * 2, height * 2))\n",
    "\n",
    "# Frame-wise upscale\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(frame_count), desc=\"Upscaling frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = torch.from_numpy(img).float().permute(2, 0, 1).unsqueeze(0).to(device) / 255.0\n",
    "        upscaled = model(img)\n",
    "        upscaled_np = upscaled.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "        upscaled_np = np.clip(upscaled_np * 255, 0, 255).astype(np.uint8)\n",
    "        out_frame = cv2.cvtColor(upscaled_np, cv2.COLOR_RGB2BGR)\n",
    "        out.write(out_frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"‚úÖ Video upscaled and saved to:\", temp_upscaled_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b55d148-6981-4591-a74e-c24c5aa8e8d0",
   "metadata": {},
   "source": [
    "## Cell 4: Merge audio + subtitles using FFmpeg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94015531-3e49-4b03-910e-d82981a73dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final video muxed successfully: naruto_upscaled.mkv\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Merge audio + subtitles\n",
    "ffmpeg_cmd = [\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", temp_upscaled_path,  # Upscaled video\n",
    "    \"-i\", input_path,          # Original audio + subs\n",
    "    \"-map\", \"0:v:0\",           # Video from new file\n",
    "    \"-map\", \"1:a?\",            # All audio from original\n",
    "    \"-map\", \"1:s?\",            # All subtitles from original\n",
    "    \"-c:v\", \"copy\",            # Video already processed\n",
    "    \"-c:a\", \"copy\",            # No re-encode\n",
    "    \"-c:s\", \"copy\",            # If softsubs (e.g. .srt/.ass), else will fail\n",
    "    final_output_path\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, check=True)\n",
    "    print(\"‚úÖ Final video muxed successfully:\", final_output_path)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"‚ùå FFmpeg failed:\")\n",
    "    print(e.stderr)\n",
    "\n",
    "# Optional: cleanup\n",
    "if os.path.exists(temp_upscaled_path):\n",
    "    os.remove(temp_upscaled_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1180625-95f3-4a2f-9fac-931d7b5a57f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6668ef9f",
   "metadata": {},
   "source": [
    "### Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e031d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch==2.2.0\n",
    "opencv-python==4.9.0.80\n",
    "tqdm==4.66.2\n",
    "numpy==1.26.4\n",
    "realesrgan==0.3.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
